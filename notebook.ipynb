{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
        "import numpy as np\n",
        "import matplotlib as plot\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.signal import wiener\n",
        "from skimage import exposure, restoration\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing data with the filtering techinques\n",
        "1. Median Filtered\n",
        "2. TopHat Filter\n",
        "3. BlackHat Filter\n",
        "4. ImAdjust Filter\n",
        "5. Weiner Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cux89exo5YKM"
      },
      "outputs": [],
      "source": [
        "# Resize images for uniformity\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# ------------------- FILTER FUNCTIONS -------------------\n",
        "\n",
        "def apply_median_filter(image, kernel_size=3):\n",
        "    return cv2.medianBlur(image, kernel_size)\n",
        "\n",
        "def apply_tophat_filter(image, kernel_size=15):\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
        "    return cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
        "\n",
        "def apply_blackhat_filter(image, kernel_size=15):\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
        "    return cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "def apply_imadjust_filter(image, low_percent=1, high_percent=99):\n",
        "    p_low, p_high = np.percentile(image, (low_percent, high_percent))\n",
        "    return exposure.rescale_intensity(image, in_range=(p_low, p_high))\n",
        "\n",
        "def apply_wiener_filter(image):\n",
        "    try:\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Normalize to float32 for Wiener\n",
        "        img_norm = gray.astype(np.float32) / 255.0\n",
        "\n",
        "        # Apply Wiener filter (3x3 window)\n",
        "        filtered = restoration.wiener(img_norm, psf=np.ones((3, 3)) / 9, balance=0.2)\n",
        "\n",
        "        # Handle NaNs, Infs\n",
        "        filtered = np.nan_to_num(filtered, nan=0.0, posinf=1.0, neginf=0.0)\n",
        "\n",
        "        # Scale back to uint8\n",
        "        filtered_uint8 = np.clip(filtered * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Convert back to RGB so ResNet can use it\n",
        "        return cv2.cvtColor(filtered_uint8, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Wiener Filter Error] {str(e)}\")\n",
        "        return image  # Return original if error\n",
        "\n",
        "\n",
        "def ensure_rgb(img):\n",
        "    if img.ndim == 2:\n",
        "        return cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    elif img.ndim == 3 and img.shape[2] == 1:\n",
        "        return np.repeat(img, 3, axis=2)\n",
        "    return img\n",
        "\n",
        "# ------------------- PROCESSING FUNCTION -------------------\n",
        "\n",
        "def show_all_filters_comparison(image_paths, labels, filter_type=\"median\"):\n",
        "    \"\"\"\n",
        "    Applies specified filter to a list of images.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of image file paths.\n",
        "        labels (list): Corresponding image labels.\n",
        "        filter_type (str): One of ['median', 'tophat', 'blackhat', 'imadjust', 'wiener'].\n",
        "\n",
        "    Returns:\n",
        "        filtered_images (np.array): Array of filtered images.\n",
        "        filtered_labels (np.array): Array of labels.\n",
        "    \"\"\"\n",
        "    filtered_images = []\n",
        "    filtered_labels = []\n",
        "\n",
        "    for path, label in tqdm(zip(image_paths, labels), total=len(image_paths), desc=f\"Applying {filter_type} filter\"):\n",
        "        original = cv2.imread(path)\n",
        "        if original is None:\n",
        "            print(f\"[Warning] Could not read: {path}\")\n",
        "            continue\n",
        "\n",
        "        original = cv2.resize(original, (224, 224))\n",
        "        original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        match filter_type.lower():\n",
        "            case \"median\":\n",
        "                filtered = apply_median_filter(original)\n",
        "            case \"tophat\":\n",
        "                gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)\n",
        "                filtered = apply_tophat_filter(gray)\n",
        "                filtered = ensure_rgb(filtered)\n",
        "            case \"blackhat\":\n",
        "                gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)\n",
        "                filtered = apply_blackhat_filter(gray)\n",
        "                filtered = ensure_rgb(filtered)\n",
        "            case \"imadjust\":\n",
        "                gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)\n",
        "                filtered = apply_imadjust_filter(gray)\n",
        "                filtered = ensure_rgb(filtered)\n",
        "            case \"wiener\":\n",
        "                filtered = apply_wiener_filter(original)  # already returns RGB\n",
        "            case _:\n",
        "                filtered = original\n",
        "\n",
        "        filtered_images.append(filtered)\n",
        "        filtered_labels.append(label)\n",
        "\n",
        "    return np.array(filtered_images), np.array(filtered_labels)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing 6 datasets for each of the filters including no filter mentioned above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_original, labels_original = show_all_filters_comparison(image_paths, labels, filter_type=\"original\")\n",
        "images_median, labels_median = show_all_filters_comparison(image_paths, labels, filter_type=\"median\")\n",
        "images_top, labels_top = show_all_filters_comparison(image_paths, labels, filter_type=\"tophat\")\n",
        "images_blackhat, labels_blackhat = show_all_filters_comparison(image_paths, labels, filter_type=\"blackhat\")\n",
        "images_imadjust, labels_imadjust = show_all_filters_comparison(image_paths, labels, filter_type=\"imadjust\")\n",
        "images_wiener, labels_wiener = show_all_filters_comparison(image_paths, labels, filter_type=\"wiener\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the pre-trained ResNet-50 with imageNet weights to extract cutting edge feaatures from the x-ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "print(\"ResNet50 loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the extract feature method\n",
        "1. Extracting the features in batches since the dataset is large, stacking each feature at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "def extract_features_in_batches(images, batch_size=32):\n",
        "    all_features = []\n",
        "\n",
        "    num_samples = len(images)\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        batch = images[i:i+batch_size]\n",
        "\n",
        "        # If grayscale, convert to 3-channel\n",
        "        if batch[0].ndim == 2 or batch[0].shape[-1] == 1:\n",
        "            batch = np.stack([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) for img in batch])\n",
        "\n",
        "        # Preprocess for ResNet\n",
        "        batch_prep = preprocess_input(batch.astype(np.float32))\n",
        "\n",
        "        # Predict\n",
        "        features = model.predict(batch_prep, verbose=0)\n",
        "\n",
        "        # Flatten features\n",
        "        features_flat = features.reshape(features.shape[0], -1)\n",
        "        all_features.append(features_flat)\n",
        "\n",
        "    return np.vstack(all_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting features for all the 6 datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_original = extract_features_in_batches(images_original)\n",
        "features_median = extract_features_in_batches(images_median)\n",
        "features_top = extract_features_in_batches(images_top)\n",
        "features_black = extract_features_in_batches(images_blackhat)\n",
        "features_imadjust = extract_features_in_batches(images_imadjust)\n",
        "features_wiener = extract_features_in_batches(images_wiener)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the vector or dimensions creating issue with KNN , applying PCA on features vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_pca_to_reduce_feature(X_scaled):\n",
        "    pca = PCA(n_components=100, svd_solver='randomized', random_state=42)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "    return X_pca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating test train split for the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def stratified_split(features, labels):\n",
        "    return train_test_split(features, labels, test_size=0.3, random_state=42, stratify=labels)\n",
        "\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = stratified_split(apply_pca_to_reduce_feature(features_original), labels_enc)\n",
        "X_train_median, X_test_median, y_train_median, y_test_median = stratified_split(apply_pca_to_reduce_feature(features_median), labels_enc)\n",
        "X_train_top, X_test_top, y_train_top, y_test_top = stratified_split(apply_pca_to_reduce_feature(features_top), labels_enc)\n",
        "X_train_black, X_test_black, y_train_black, y_test_black = stratified_split(apply_pca_to_reduce_feature(features_black), labels_enc)\n",
        "X_train_wiener, X_test_wiener, y_train_wiener, y_test_wiener = stratified_split(apply_pca_to_reduce_feature(features_wiener), labels_enc)\n",
        "X_train_imadjust, X_test_imadjust, y_train_imadjust, y_test_imadjust = stratified_split(apply_pca_to_reduce_feature(features_imadjust), labels_enc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a dictionary to maintain information about the different Scaling techinques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "scalers = {\n",
        "    \"Standard\": StandardScaler(),\n",
        "    \"MinMax\": MinMaxScaler(),\n",
        "    \"Robust\": RobustScaler()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining KNN classifier for different distance metrics distances=[\"euclidean\",\"manhattan\",\"chebyshev\",\"minkowski\",\"cosine\",\"correlation\",\"canberra\",\"braycurtis\"] and [1,3,5,7] neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_knn(X_train, X_test, y_train, y_test, scalers, metrics,distances):\n",
        "    results = []\n",
        "\n",
        "    for scaler_name, scaler in scalers.items():\n",
        "        # Fit and transform data\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        for ne in [1,3,5,7]:\n",
        "            for metric in distances:\n",
        "                knn = KNeighborsClassifier(n_neighbors=ne,n_jobs=1,metric=metric)\n",
        "                knn.fit(X_train_scaled, y_train)\n",
        "                y_pred = knn.predict(X_test_scaled)\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "                results.append({\n",
        "                    \"Scaler\": scaler_name,\n",
        "                    \"Distance\": metric,\n",
        "                    \"Accuracy\": acc,\n",
        "                    \"Neighbors\":ne\n",
        "                })\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing 6 results vectors each corresponds to respective filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_orig = evaluate_knn(X_train_orig, X_test_orig, y_train_orig, y_test_orig, scalers, metrics,distances)\n",
        "results_median = evaluate_knn(X_train_median, X_test_median, y_train_median, y_test_median, scalers, metrics,distances)\n",
        "results_black = evaluate_knn(X_train_black, X_test_black, y_train_black, y_test_black, scalers, metrics,distances)\n",
        "results_top = evaluate_knn(X_train_top, X_test_top, y_train_top, y_test_top, scalers, metrics,distances)\n",
        "results_wiener = evaluate_knn(X_train_wiener, X_test_wiener, y_train_wiener, y_test_wiener, scalers, metrics,distances)\n",
        "results_imadjust = evaluate_knn(X_train_imadjust, X_test_imadjust, y_train_imadjust, y_test_imadjust, scalers, metrics,distances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Writing a function to extract measure metrics for the above results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_knn_multiclass_roc(X_train, X_test, y_train, y_test, scalers, metrics, distances):\n",
        "    classes = np.unique(y_train)\n",
        "    y_test_bin = label_binarize(y_test, classes=classes)\n",
        "\n",
        "    results = []\n",
        "    roc_data = {}\n",
        "    all_preds = {}\n",
        "\n",
        "    for scaler_name, scaler in scalers.items():\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        for ne in [1, 3, 5, 7]:\n",
        "            for metric in distances:\n",
        "                knn = KNeighborsClassifier(n_neighbors=ne, metric=metric, n_jobs=1)\n",
        "                knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "                y_prob = knn.predict_proba(X_test_scaled)\n",
        "                y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "                fpr = dict()\n",
        "                tpr = dict()\n",
        "                roc_auc = dict()\n",
        "                for i, cls in enumerate(classes):\n",
        "                    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
        "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "                fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_prob.ravel())\n",
        "                roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "                results.append({\n",
        "                    \"Scaler\": scaler_name,\n",
        "                    \"Distance\": metric,\n",
        "                    \"Neighbors\": ne,\n",
        "                    \"Accuracy\": acc,\n",
        "                    \"AUC_micro\": roc_auc[\"micro\"],\n",
        "                    **{f\"AUC_class_{cls}\": roc_auc[i] for i, cls in enumerate(classes)}\n",
        "                })\n",
        "\n",
        "                key = (scaler_name, metric, ne)\n",
        "                roc_data[key] = {\n",
        "                    \"fpr\": fpr,\n",
        "                    \"tpr\": tpr,\n",
        "                    \"roc_auc\": roc_auc,\n",
        "                    \"classes\": classes\n",
        "                }\n",
        "\n",
        "                all_preds[key] = {\n",
        "                    \"y_test\": y_test,\n",
        "                    \"y_pred\": y_pred\n",
        "                }\n",
        "\n",
        "    return results, roc_data, all_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generating all the resukts, predictions and ROC-AUC data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_orig,roc_data_orig,all_preds_orig = evaluate_knn_multiclass_roc(X_train_orig, X_test_orig, y_train_orig, y_test_orig, scalers, metrics,distances)\n",
        "results_median,roc_data_median,all_preds_median = evaluate_knn_multiclass_roc(X_train_median, X_test_median, y_train_median, y_test_median, scalers, metrics,distances)\n",
        "results_top,roc_data_top,all_preds_top = evaluate_knn_multiclass_roc(X_train_top, X_test_top, y_train_top, y_test_top, scalers, metrics,distances)\n",
        "results_black,roc_data_black,all_preds_black = evaluate_knn_multiclass_roc(X_train_black, X_test_black, y_train_black, y_test_black, scalers, metrics,distances)\n",
        "results_imadjust,roc_data_imadjust,all_preds_imadjust = evaluate_knn_multiclass_roc(X_train_imadjust, X_test_imadjust, y_train_imadjust, y_test_imadjust, scalers, metrics,distances)\n",
        "results_wiener,roc_data_wiener,all_preds_wiener = evaluate_knn_multiclass_roc(X_train_wiener, X_test_wiener, y_train_wiener, y_test_wiener, scalers, metrics,distances)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generating the pandas data csv files for each of the scaler methods containing information about fiters, values of K , distance metrics and there AUC scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example filter names and results from evaluate_knn_multiclass_roc\n",
        "filters = ['Original', 'Median', 'Tophat', 'Blackhat', 'Imadjust', 'Wiener']\n",
        "results_all = [results_orig, results_median, results_top, results_black, results_imadjust, results_wiener]\n",
        "\n",
        "# Dictionary to collect results per scaler\n",
        "scaler_tables = {}\n",
        "\n",
        "for filter_name, results in zip(filters, results_all):\n",
        "    for row in results:\n",
        "        scaler_name = row['Scaler']\n",
        "\n",
        "        # Build base row\n",
        "        row_data = {\n",
        "            \"Filter\": filter_name,\n",
        "            \"Distance\": row[\"Distance\"],\n",
        "            \"K\": row[\"Neighbors\"],\n",
        "            \"Accuracy\": round(row[\"Accuracy\"], 4),\n",
        "            \"AUC_micro\": round(row[\"AUC_micro\"], 4),\n",
        "        }\n",
        "\n",
        "        # Add class-wise AUCs\n",
        "        for key in row:\n",
        "            if key.startswith(\"AUC_class_\"):\n",
        "                class_label = key.replace(\"AUC_class_\", \"\")\n",
        "                row_data[f\"AUC_{class_label}\"] = round(row[key], 4)\n",
        "\n",
        "        # Store by scaler\n",
        "        if scaler_name not in scaler_tables:\n",
        "            scaler_tables[scaler_name] = []\n",
        "        scaler_tables[scaler_name].append(row_data)\n",
        "\n",
        "# Convert and save each scaler's table\n",
        "for scaler_name, rows in scaler_tables.items():\n",
        "    df = pd.DataFrame(rows)\n",
        "    df_sorted = df.sort_values(by=[\"Filter\", \"K\"])\n",
        "    \n",
        "    filename = f\"knn_results_{scaler_name.lower()}.csv\"\n",
        "    df_sorted.to_csv(filename, index=False)\n",
        "    print(f\"[Saved] {filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generating method for creating confusion metrics for each filter type for each type of scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filters = ['Original', 'Median', 'Black hat', 'top hat', 'imadjust', 'wiener']\n",
        "class_labels = [\"COVID-19\", \"Normal\", \"Pneumonia\"]\n",
        "\n",
        "# Ensure root directory exists\n",
        "#os.makedirs('/kaggle/working/confusion_matrix', exist_ok=True)\n",
        "\n",
        "for fil in filters:\n",
        "    # Create directory for the filter\n",
        "    #filter_dir = os.path.join('/kaggle/working/confusion_matrix', fil.replace(\" \", \"_\"))\n",
        "    #os.makedirs(filter_dir, exist_ok=True)\n",
        "\n",
        "    for scaler_name in scalers:\n",
        "        for dist in distances:\n",
        "            key = (scaler_name, dist.lower(), 5)\n",
        "\n",
        "            # Get predictions and labels for the given filter\n",
        "            if fil == \"Original\":\n",
        "                y_test = all_preds_orig[key]['y_test']\n",
        "                y_pred = all_preds_orig[key]['y_pred']\n",
        "            elif fil == \"Median\":\n",
        "                y_test = all_preds_median[key]['y_test']\n",
        "                y_pred = all_preds_median[key]['y_pred']\n",
        "            elif fil == \"Black hat\":\n",
        "                y_test = all_preds_black[key]['y_test']\n",
        "                y_pred = all_preds_black[key]['y_pred']\n",
        "            elif fil == \"top hat\":\n",
        "                y_test = all_preds_top[key]['y_test']\n",
        "                y_pred = all_preds_top[key]['y_pred']\n",
        "            elif fil == \"imadjust\":\n",
        "                y_test = all_preds_imadjust[key]['y_test']\n",
        "                y_pred = all_preds_imadjust[key]['y_pred']\n",
        "            elif fil == \"wiener\":\n",
        "                y_test = all_preds_wiener[key]['y_test']\n",
        "                y_pred = all_preds_wiener[key]['y_pred']\n",
        "            else:\n",
        "                continue  # Unknown filter, skip\n",
        "\n",
        "            # Compute and display confusion matrix\n",
        "            cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n",
        "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(6, 6))\n",
        "            disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
        "            plt.title(f'Confusion Matrix: {fil} - {scaler_name} - {dist} - k=5')\n",
        "            plt.grid(False)\n",
        "\n",
        "            # Save the figure\n",
        "            # filename = f'{scaler_name}_{dist}_k5.png'\n",
        "            # save_path = os.path.join(filter_dir, filename)\n",
        "            # plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            # plt.close()  # Prevent display in notebook\n",
        "\n",
        "            #print(f\"[Saved] {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot function to display the ROC-AUC curve for the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_comparative_roc(roc_data_list, labels, scaler='StandardScaler', distance='euclidean', neighbors=7, class_to_plot=0):\n",
        "    \"\"\"\n",
        "    roc_data_list: list of roc_data dictionaries from evaluate_knn_multiclass_roc\n",
        "    labels: list of labels for the datasets (e.g. ['Original', 'Median Filtered', 'NLM Filtered'])\n",
        "    scaler: scaler name to filter plots by\n",
        "    distance: distance metric to filter plots by\n",
        "    neighbors: number of neighbors to filter plots by\n",
        "    class_to_plot: index of class to plot ROC for (default: first class)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    \n",
        "    for roc_data, label in zip(roc_data_list, labels):\n",
        "        key = (scaler, distance,7)\n",
        "        if key not in roc_data:\n",
        "            print(f\"Warning: Key {key} not found in roc_data\")\n",
        "            continue\n",
        "\n",
        "        data = roc_data[key]\n",
        "        fpr = data['fpr']\n",
        "        tpr = data['tpr']\n",
        "        roc_auc = data['roc_auc']\n",
        "        print(\"LABLEL\",label)\n",
        "\n",
        "        # Plot ROC curve for the selected class\n",
        "        plt.plot(fpr[class_to_plot], tpr[class_to_plot], lw=2, label=f'{label} (AUC = {roc_auc[class_to_plot]:.3f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve Comparison (Class {class_to_plot}, {scaler}, {distance})')\n",
        "    plt.legend(loc='lower right')\n",
        "    \n",
        "    filename = f'class{class_to_plot}_{scaler}_{distance}_k{neighbors}.png'\n",
        "    save_path = os.path.join(\"/kaggle/working/output_plots\", filename)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"[Saved] {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.close()  # Close the plot to free memory\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating ROC-AUC curves for each types of scaling and each type of distance metrics used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scalers = ['Standard','Robust','MinMax']\n",
        "roc_data_list = [roc_data_orig, roc_data_median, roc_data_top,roc_data_black,roc_data_imadjust,roc_data_wiener]\n",
        "labels = ['Original', 'Median Filtered', 'Top Filtered','Black','Imadjust','Wiener']\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(len(distances)):\n",
        "        plot_comparative_roc(roc_data_list,labels,scaler=scalers[i],distance=distances[j],neighbors=5,class_to_plot=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GRad IO (UI design)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ===== 1. Load Pretrained ResNet and Remove FC Layer =====\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove final classification layer\n",
        "resnet.eval()\n",
        "\n",
        "# ===== 2. Define Image Transform Pipeline for ResNet =====\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# ===== 3. Define imadjust-style Contrast Enhancement =====\n",
        "def imadjust(img):\n",
        "    img = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "# ===== 4. Feature Extraction Function =====\n",
        "def extract_features(image_path):\n",
        "    img = Image.open(image_path).convert('L')  # grayscale\n",
        "    img = np.array(img)\n",
        "    img = imadjust(img)\n",
        "\n",
        "    # Convert grayscale to 3 channels by stacking\n",
        "    img = np.stack([img]*3, axis=-1)  # shape: (H, W, 3)\n",
        "\n",
        "    img = transform(img).unsqueeze(0)  # shape: (1, 3, 224, 224)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features = resnet(img).squeeze().numpy()  # shape: (2048,)\n",
        "    return features\n",
        "\n",
        "# ===== 5. Build Dataset from Folders =====\n",
        "data_dir = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/train\"  # update if your dataset path is different\n",
        "labels = []\n",
        "features = []\n",
        "\n",
        "for label in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    if not os.path.isdir(class_dir):\n",
        "        continue\n",
        "    for file in tqdm(os.listdir(class_dir), desc=f\"Processing {label}\"):\n",
        "        path = os.path.join(class_dir, file)\n",
        "        try:\n",
        "            feat = extract_features(path)\n",
        "            features.append(feat)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing {path}: {e}\")\n",
        "\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# ===== 6. PCA and Scaling =====\n",
        "pca = PCA(n_components=100, svd_solver='randomized', random_state=42)\n",
        "features_pca = pca.fit_transform(features)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_pca)\n",
        "\n",
        "# ===== 7. Save Dataset and Transformers =====\n",
        "np.savez(\"xray_knn_dataset.npz\", X=features_scaled, y=labels)\n",
        "np.save(\"pca_components.npy\", pca.components_)\n",
        "np.save(\"scaler_mean_std.npy\", np.vstack([scaler.mean_, scaler.scale_]))\n",
        "\n",
        "print(\"✅ Saved features to 'xray_knn_dataset.npz'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Link for our kaggle notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://www.kaggle.com/code/imdevml/effect-of-noise-filtering-feature-scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
