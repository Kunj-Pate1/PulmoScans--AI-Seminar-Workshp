{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
        "import numpy as np\n",
        "import matplotlib as plot\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing data with the filtering techinques\n",
        "1. Median Filtered\n",
        "2. NLM Filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cux89exo5YKM"
      },
      "outputs": [],
      "source": [
        "# Resize images for uniformity\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Noise filtering functions\n",
        "def apply_median_filter(images):\n",
        "    return np.array([cv2.medianBlur(img, 3) for img in images])\n",
        "\n",
        "def apply_nlm_filter(images):\n",
        "    # Convert to float, estimate sigma, apply NLM\n",
        "    filtered = []\n",
        "    for img in images:\n",
        "        sigma_est = np.mean(estimate_sigma(img, multichannel=False))\n",
        "        denoised = denoise_nl_means(img, h=1.15*sigma_est, fast_mode=True,\n",
        "                                    patch_size=5, patch_distance=3, multichannel=False)\n",
        "        filtered.append((denoised * 255).astype(np.uint8))\n",
        "    return np.array(filtered)\n",
        "\n",
        "# Preprocess function with denoising\n",
        "def preprocess_and_filter(images, labels, method=\"original\"):\n",
        "    processed_images = []\n",
        "    new_labels = []\n",
        "\n",
        "    for path, label in tqdm(zip(images, labels), total=len(images)):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if method == \"median\":\n",
        "            img = apply_median_filter(img)\n",
        "        elif method == \"nlm\":\n",
        "            img = apply_nlm_filter(img)\n",
        "        # else keep original\n",
        "\n",
        "        processed_images.append(img)\n",
        "        new_labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(new_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing 3 datasets\n",
        "1. Original\n",
        "2. Median Filter\n",
        "3. NLM Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_original, labels_original = preprocess_and_filter(image_paths, labels, method=\"original\")\n",
        "images_median, labels_median = preprocess_and_filter(image_paths, labels, method=\"median\")\n",
        "images_nlm, labels_nlm = preprocess_and_filter(image_paths, labels, method=\"nlm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the pre-trained ResNet-50 with imageNet weights to extract cutting edge feaatures from the x-ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "print(\"ResNet50 loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the extract feature method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(images):\n",
        "    # Preprocess for ResNet50\n",
        "    images_prep = preprocess_input(images)\n",
        "    # Extract features\n",
        "    features = model.predict(images_prep, batch_size=32, verbose=1)\n",
        "    # Flatten to 1D vectors\n",
        "    features_flat = features.reshape(features.shape[0], -1)\n",
        "    return features_flat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting features for all the 3 datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_original = extract_features(images_original)\n",
        "features_median = extract_features(images_median)\n",
        "features_nlm = extract_features(images_nlm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the vector or dimensions creating issue with KNN , applying PCA on features vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_pca_to_reduce_feature(X_scaled):\n",
        "    pca = PCA(n_components=100, svd_solver='randomized', random_state=42)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "    return X_pca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating test train split for the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stratified_split(features, labels):\n",
        "    return train_test_split(features, labels, test_size=0.7, random_state=42, stratify=labels)\n",
        "\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = stratified_split(apply_pca_to_reduce_feature(features_original), labels_enc)\n",
        "X_train_median, X_test_median, y_train_median, y_test_median = stratified_split(apply_pca_to_reduce_feature(features_median), labels_enc)\n",
        "X_train_nlm, X_test_nlm, y_train_nlm, y_test_nlm = stratified_split(apply_pca_to_reduce_feature(features_nlm), labels_enc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a dictionary to maintain information about the different Scaling techinques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "scalers = {\n",
        "    \"Standard\": StandardScaler(),\n",
        "    \"MinMax\": MinMaxScaler(),\n",
        "    \"Robust\": RobustScaler()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining KNN classifier for different distance metrics distances=[\"euclidean\",\"manhattan\",\"chebyshev\",\"minkowski\",\"cosine\",\"correlation\",\"canberra\",\"braycurtis\"] and [1,3,5,7] neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_knn(X_train, X_test, y_train, y_test, scalers, metrics,distances):\n",
        "    results = []\n",
        "\n",
        "    for scaler_name, scaler in scalers.items():\n",
        "        # Fit and transform data\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        for ne in [1,3,5,7]:\n",
        "            for metric in distances:\n",
        "                knn = KNeighborsClassifier(n_neighbors=ne,n_jobs=1,metric=metric)\n",
        "                knn.fit(X_train_scaled, y_train)\n",
        "                y_pred = knn.predict(X_test_scaled)\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "                results.append({\n",
        "                    \"Scaler\": scaler_name,\n",
        "                    \"Distance\": metric,\n",
        "                    \"Accuracy\": acc,\n",
        "                    \"Neighbors\":ne\n",
        "                })\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing 3 results vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_orig = evaluate_knn(X_train_orig, X_test_orig, y_train_orig, y_test_orig, scalers, metrics,distances)\n",
        "results_median = evaluate_knn(X_train_median, X_test_median, y_train_median, y_test_median, scalers, metrics)\n",
        "results_nlm = evaluate_knn(X_train_nlm, X_test_nlm, y_train_nlm, y_test_nlm, scalers, metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generating DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
